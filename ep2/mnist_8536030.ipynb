{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "import util\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download MNIST e separar apenas os exemplos de dígitos 0 e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20737, 784) (20737,)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original') \n",
    "vals = set()\n",
    "for idx, label in enumerate(mnist.target):\n",
    "    if (label == 0 or label == 6 or label == 9):\n",
    "        vals.add(idx)\n",
    "data_mnist = np.array([mnist.data[idx] for idx in vals])\n",
    "label_mnist = np.array([mnist.target[idx] for idx in vals])\n",
    "print(data_mnist.shape, label_mnist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando e visualizando um subdataset com n exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data, new_labels = util.get_samples(data_mnist, \n",
    "                                        label_mnist, \n",
    "                                        size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util.plot_img_grid(new_data, \n",
    "#                   new_labels, \n",
    "#                   max_cols = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippet simples que itera sobre uma lista de vetores de imagem e mostra eles em tela com uma pausa de 1 segundo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(new_labels)):\n",
    "#    util.array_imshow(new_data[i], new_labels[i])\n",
    "#    plt.pause(1)\n",
    "#    display.clear_output(wait=True)\n",
    "#    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação dos dígitos 0, 6 e 9\n",
    "\n",
    "Fiz três classificadores que usam a mesma ideia. Suponha que $w$ e $h$ são as dimensões da imagem, e chame de $r(x,y)$ toda a região retangular de tamanho $d_l\\times d_c$ e posição $(x, y)$. Vou chamar de $\\mu_{x,y}$ a média dos pixels de cada região $r(x,y)$.\n",
    "\n",
    "As diferenças de cada classificador são as restrições.\n",
    "\n",
    "**No segundo (`class_t = 1`):** (mais simples)\n",
    "\n",
    "Tomo uma amostra de $m$ imagens e apenas seleciono as regiões que não se sobreponham. Então, para toda posição $(d_r.i, d_c.j)$, onde $i=\\{0,\\ldots,\\frac{w}{d_r}\\}$ e $j=\\{0,\\ldots,\\frac{w}{d_c}\\}$, pego estas regiões e computo as médias, separando as médias por seus rótulos $l$. Para classificar uma imagem, comparo cada média de região das amostras com a da imagem a ser classificada. Então, para cada $\\hat{\\mu}_i^l(x,y)$ e $\\mu(x,y)$, as médias da i-ésima amostra com o rótulo $l$ na região $r(x,y)$ e da imagem a ser classificada, acho o erro:\n",
    "\n",
    "$$e_i^l(x,y)=|\\hat{\\mu}_i^l(x,y)-\\mu(x,y)|$$\n",
    "\n",
    "E somo todos os erros:\n",
    "\n",
    "$$\\sum_{i=0}^m e_i^l(x,y)$$\n",
    "\n",
    "Quero escolher o rótulo de menor erro, então acho:\n",
    "\n",
    "$${\\arg\\max}_{l\\in L}\\sum_{i=0}^m e_i^l(x,y)\\text{, onde $L$ é o conjunto de rótulos.}$$\n",
    "\n",
    "O $l$ resultante é a classificação de menor erro.\n",
    "\n",
    "**No primeiro (`class_t = 0`):**\n",
    "\n",
    "Em uma amostra de $m$ imagens, fixo um tamanho $(d_r,d_c)$ e percorro todas as possíveis regiões de tamanho $(d_r,d_c)$ da imagem (mesmo as que se sobrepõe). Assim como no segundo, acho o erro subtraindo as médias da amostra com a da imagem a ser classificada.\n",
    "\n",
    "**No terceiro (`class_t = 2`):**\n",
    "\n",
    "Para o terceiro, ao invés de fixar os tamanhos das regiões da imagem, computo todas as médias de regiões retangulares de tamanho maior ou igual a $(d_r,d_c)$. Então agora vamos ter de considerar todas as regiões $r(x,y,p_w,p_h)$, onde $p_w$ e $p_h$ são a largura e a altura da região respectivamente. Além disso, crio um vetor $W$ de peso. Como certas regiões tem maior importância que outras, $W$ define uma ponderação para cada região retangular da imagem. Seja $E_i^l$ o vetor de erros $e_i^l(x,y,p_w,p_h)$ onde a região $r(x,y,p_w,p_h)$ é indexada através de alguma função injetora $f:\\mathbb{Z}_w\\times\\mathbb{Z}_h\\times\\mathbb{Z}_w\\times\\mathbb{Z}_h\\to\\mathbb{Z}_k$. Achar o classificador é então minimizar a soma:\n",
    "\n",
    "$${\\arg\\max}_{l\\in L} \\sum_i\\sum_j E_i^l\\cdot W$$\n",
    "\n",
    "Substituindo $M_j^{(i,l)}=E_i^l\\cdot W$, com $j$ indexando os elementos de $M$, queremos achar o rótulo com menor erro:\n",
    "\n",
    "$${\\arg\\max}_{l\\in L} \\sum_{i=0}^m \\sum_{j=0}^n M_j^i$$\n",
    "\n",
    "Agora só falta provar que $f$ é injetora. A função injetora \"mágica\" $f$ é a função `encode`. Ela toma uma quádrupla $(x_1,y_1,x_2,y_2)$ e retorna um inteiro. Definimos $f$ como:\n",
    "\n",
    "$$f(x_1,y_1,x_2,y_2) = ((y_1\\cdot w+x_1)w+x_2)h+y_2$$\n",
    "\n",
    "Onde $w$ e $h$ são constantes positivas maiores que zero (no nosso caso as dimensões da imagem). Vamos provar que $f$ é injetora:\n",
    "\n",
    "*Dem.*\n",
    "\n",
    "Queremos mostrar que se $f(a, b, c, d) = f(a', b', c', d')$, então $(a, b, c, d) = (a', b', c', d')$. Tomamos $a, c, a', c'\\in\\mathbb{Z_w}$ e $b, d, b', d'\\in\\mathbb{Z_h}$, e suponhamos que $f(a, b, c, d)=f(a', b', c', d')$. Então:\n",
    "\n",
    "$$((bw+a)w+c)h+d = ((b'w+a')w+c')h+d'$$\n",
    "\n",
    "Desenvolvendo, temos:\n",
    "\n",
    "$$w^2 h(b-b')+wh(a-a')+h(c-c')+(d-d')=0$$\n",
    "\n",
    "Mas $w,h > 0$. Então, é necessário que $a-a'=0$, $b-b'=0$, $c-c'=0$, $d-d'=0$ para que $f(a,b,c,d)=f(a',b',c',d')$. Disso temos que $a=a'$, $b=b'$, $c=c'$, $d=d'$. Portanto, segue que $f$ é injetora.\n",
    "$$\\tag*{$\\blacksquare$}$$\n",
    "\n",
    "O terceiro classificador, apesar de ser mais geral, demora muito mais, já que pega todos as possíveis regiões retangulares da imagem.\n",
    "\n",
    "# Resultados\n",
    "\n",
    "Os dois primeiros classificadores tiveram resultados mais ou menos iguais. Para tamanho 1000 e amostra 100, os três ficaram com .85, .90 de acurácia. O problema foi quando aumenta-se o tamanho da amostra. Como o erro vai acumulando, ter uma amostra grande, contra-intuitivamente, é pior. Uma melhoria seria pegar a média das médias, já que o erro se estabilizaria no final. Os três tiveram dificuldade em diferenciar o dígito 0, mas fizeram poucos erros quando classificaram 6 e 9. Os resultados foram mais ou menos iguais para os três classificadores, mas o terceiro demorou muito mais. Os resultados ficaram muito piores quando aumentou-se a amostra e o dataset de treino. Uma melhoria seria ajustar o $W$ para dar mais importância a certas regiões. Infelizmente, como o terceiro classificador demora demais, não deu tempo para se ajustar tão bem os valores de $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data, sample_label = util.get_samples(data_mnist, label_mnist, size=100)\n",
    "img_w, img_h = 28, 28\n",
    "class_t = 0\n",
    "R = {}\n",
    "\n",
    "def encode(x1, y1, x2, y2):\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    return int(((y1*img_w+x1)*img_w+x2)*img_h+y2)\n",
    "def decode(k):\n",
    "    y2 = k%img_h\n",
    "    c = (k-y2)/img_h\n",
    "    x2 = c%img_w\n",
    "    c = (c-x2)/img_w\n",
    "    x1 = c%img_w\n",
    "    y1 = (c-x1)/img_w\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def get_index(x1, y1, x2, y2):\n",
    "    return R[encode(x1, y1, x2, y2)]\n",
    "                \n",
    "def get_params(dx, dy, n, min_w=2, min_h=2):\n",
    "    S = {}\n",
    "    if class_t == 0:\n",
    "        for i in range(len(sample_data)):\n",
    "            s = []\n",
    "            d = util.array2img(sample_data[i])\n",
    "            for x in range(0, img_w-dx):\n",
    "                for y in range(0, img_h-dy):\n",
    "                    s.append(np.mean(d[x:x+dx, y:y+dy]))\n",
    "            l = sample_label[i]\n",
    "            if not (l in S):\n",
    "                S[l] = []\n",
    "            S[l].append(s)\n",
    "        return S, dx, dy\n",
    "    elif class_t == 1:\n",
    "        dx, dy = int(img_w/n), int(img_h/n)\n",
    "        for i in range(len(sample_data)):\n",
    "            s = []\n",
    "            d = util.array2img(sample_data[i])\n",
    "            for x in range(0, n-1):\n",
    "                for y in range(0, n-1):\n",
    "                    s.append(np.mean(d[x*dx:(x+1)*dx, y*dy:(y+1)*dy]))\n",
    "                    \n",
    "            l = sample_label[i]\n",
    "            if not (l in S):\n",
    "                S[l] = []\n",
    "            S[l].append(s)\n",
    "        return S, dx, dy, n\n",
    "    else:\n",
    "        m = 0\n",
    "        for x in range(0, img_w):\n",
    "            for y in range(0, img_h):\n",
    "                for a in range(x+min_w, img_w):\n",
    "                    for b in range(y+min_h, img_h):\n",
    "                        x1, y1, x2, y2 = x, y, a, b\n",
    "                        #print(x1, y1, x2, y2, \"=\", m)\n",
    "                        R[encode(x1, y1, x2, y2)] = m\n",
    "                        m += 1\n",
    "        for i in range(len(sample_data)):\n",
    "            s = []\n",
    "            d = util.array2img(sample_data[i])\n",
    "            for x in range(0, img_w):\n",
    "                for y in range(0, img_h):\n",
    "                    for a in range(x+min_w, img_w):\n",
    "                        for b in range(y+min_h, img_h):\n",
    "                            x1, y1, x2, y2 = x, y, a, b\n",
    "                            s.append(np.mean(d[x1:x2, y1:y2]))\n",
    "            l = sample_label[i]\n",
    "            if not (l in S):\n",
    "                S[l] = []\n",
    "            S[l].append(s)\n",
    "        return S, m\n",
    "    \n",
    "W = None\n",
    "min_w, min_h = 2, 2\n",
    "def initialize_classifier(dx=2, dy=2, n=14, w=2, h=2):\n",
    "    min_w, min_h = w, h\n",
    "    W = None\n",
    "    if class_t == 0:\n",
    "        S, dx, dy = get_params(dx, dy, n)\n",
    "        return S, dx, dy\n",
    "    elif class_t == 1:\n",
    "        S, dx, dy, nS = get_params(dx, dy, n)\n",
    "        return S, dx, dy, nS\n",
    "    else:\n",
    "        S, m = get_params(dx, dy, n, min_w, min_h)\n",
    "        W = np.full(m, 0.01)\n",
    "        # Da mais importancia as regioes seguintes:\n",
    "        W[get_index(0, 0, img_w/2, img_h-1)] = 0.25\n",
    "        W[get_index(img_w/2, 0, img_w-1, img_h-1)] = 0.25\n",
    "        W[get_index(0, 0, img_w-1, img_h/2)] = 0.25\n",
    "        W[get_index(0, img_h/2, img_w-1, img_h-1)] = 0.25\n",
    "        W[get_index(10, 10, 18, 18)] = 0.25\n",
    "        return S\n",
    "\n",
    "def classifier(flat_img):\n",
    "    img = util.array2img(flat_img)\n",
    "    P = []\n",
    "    if class_t == 0:\n",
    "        for x in range(0, img_w-dx):\n",
    "            for y in range(0, img_h-dy):\n",
    "                P.append(np.mean(img[x:x+dx, y:y+dy]))\n",
    "    elif class_t == 1:\n",
    "        for x in range(0, nS-1):\n",
    "            for y in range(0, nS-1):\n",
    "                P.append(np.mean(img[x*dx:(x+1)*dx, y*dy:(y+1)*dy]))\n",
    "    else:\n",
    "        for x in range(0, img_w):\n",
    "            for y in range(0, img_h):\n",
    "                for a in range(x+min_w, img_w):\n",
    "                    for b in range(y+min_h, img_h):\n",
    "                        P.append(np.mean(img[x:a, y:b]))\n",
    "    ml, l = -1, -1\n",
    "    for k, samples in S.items():\n",
    "        d = 0\n",
    "        for i in range(len(samples)):\n",
    "            X = np.asarray(samples[i])-np.asarray(P)\n",
    "            if class_t == 2:\n",
    "                X = X.dot(W)\n",
    "            d += np.sum(np.absolute(X))\n",
    "        if (ml == -1 or d < l):\n",
    "            l, ml = d, k\n",
    "    return ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(true_labels, predicted_labels, normalized=True):\n",
    "    assert true_labels.shape[0] == predicted_labels.shape[0], \"Original labels and predicted labels \\\n",
    "                                                               doesn't match in rows number\"\n",
    "    util.plot_confusion_matrix_metrics(true_labels=true_labels,\n",
    "                                       predicted_labels=predicted_labels,\n",
    "                                       normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1b5ad5a92dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclass_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-de2db66f9209>\u001b[0m in \u001b[0;36minitialize_classifier\u001b[0;34m(dx, dy, n, w, h)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Da mais importancia as regioes seguintes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-de2db66f9209>\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(dx, dy, n, min_w, min_h)\u001b[0m\n\u001b[1;32m     65\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmin_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2957\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Make this warning show up first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_t = 3\n",
    "S = initialize_classifier(w=2, h=2)\n",
    "predictions = predictor(new_data, classifier=classifier)\n",
    "evaluator(true_labels=new_labels, predicted_labels=predictions)\n",
    "class_t = 0\n",
    "S, dx, dy = initialize_classifier(5, 5, 14)\n",
    "predictions = predictor(new_data, classifier=classifier)\n",
    "evaluator(true_labels=new_labels, predicted_labels=predictions)\n",
    "class_t = 1\n",
    "S, dx, dy, nS = initialize_classifier(2, 2, 7)\n",
    "predictions = predictor(new_data, classifier=classifier)\n",
    "evaluator(true_labels=new_labels, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
